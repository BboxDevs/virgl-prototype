{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "479a9372",
   "metadata": {},
   "source": [
    "**Resumes**\n",
    "\n",
    "Sorry for downloading your resume. I need it for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4813fdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume = \"./resumes/cw-resume-jv1.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8548b20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume = \"./resumes/Jerick-Iquin.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1477247",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume = \"./resumes/Kenneth Lee Resume.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b523ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume = \"./resumes/Justin Lam - Resume - vPortfolio.pdf\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b2754e85",
   "metadata": {},
   "source": [
    "**Using pymupdf**\n",
    "\n",
    "- Best one so far. Plus you can organize it through blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7dc6e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz # this is from pymupdf\n",
    "from unidecode import unidecode\n",
    "import pandas as pd\n",
    "import pprint\n",
    "\n",
    "doc = fitz.open(resume)\n",
    "block_dict = {}\n",
    "\n",
    "page_num = 0\n",
    "\n",
    "for page in doc:\n",
    "    page_num += 1\n",
    "    file_dict = page.get_text('dict')\n",
    "    # block format (x0, y0, x1, y1, string, block_no, block_type)\n",
    "    block = file_dict['blocks']\n",
    "    block_dict[page_num] = block    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4504e77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "spans = pd.DataFrame(columns=['xmin', 'ymin', 'xmax', 'ymax', 'text', 'tag'])\n",
    "rows = []\n",
    "\n",
    "for page_num, blocks in block_dict.items():\n",
    "    for block in blocks:\n",
    "        if block['type'] == 0:\n",
    "            for line in block['lines']:\n",
    "                for span in line['spans']:\n",
    "                    xmin, ymin, xmax, ymax = list(span['bbox'])\n",
    "                    font_size = span['size']\n",
    "                    text = unidecode(span['text'])\n",
    "                    span_font = span['font']\n",
    "                    is_upper = False\n",
    "                    is_bold = False \n",
    "\n",
    "                    if \"bold\" in span_font.lower():\n",
    "                        is_bold = True \n",
    "\n",
    "                    if re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", text).isupper():\n",
    "                        is_upper = True\n",
    "\n",
    "                    if text.replace(\" \",\"\") !=  \"\":\n",
    "                        rows.append((xmin, ymin, xmax, ymax, text, is_upper, is_bold, span_font, font_size))\n",
    "\n",
    "span_df = pd.DataFrame(rows, columns=['xmin','ymin','xmax','ymax', 'text', 'is_upper','is_bold','span_font', 'font_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5dbaf4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "span_scores = []\n",
    "span_num_occur = {}\n",
    "special = '[(_:/,#%\\=@)]'\n",
    "\n",
    "for index, span_row in span_df.iterrows():\n",
    "    score = round(span_row.font_size)\n",
    "    text = span_row.text\n",
    "\n",
    "    if not re.search(special, text):\n",
    "        if span_row.is_bold:\n",
    "            score += 1\n",
    "\n",
    "        if span_row.is_upper:\n",
    "            score += 1\n",
    "    \n",
    "    span_scores.append(score)\n",
    "\n",
    "values, counts = np.unique(span_scores, return_counts=True)\n",
    "\n",
    "style_dict = {}\n",
    "\n",
    "for value, count in zip(values, counts):\n",
    "    style_dict[value] = count\n",
    "\n",
    "sorted(style_dict.items(), key=lambda x: x[1])\n",
    "\n",
    "p_size = max(style_dict, key=style_dict.get)\n",
    "\n",
    "idx = 0\n",
    "tag = {}\n",
    "\n",
    "for size in sorted(values, reverse = True):\n",
    "    idx += 1\n",
    "\n",
    "    if size == p_size:\n",
    "        idx = 0\n",
    "        tag[size] = 'p'\n",
    "\n",
    "    if size > p_size:\n",
    "        tag[size] = 'h{0}'.format(idx)\n",
    "    \n",
    "    if size < p_size:\n",
    "        tag[size] = 's{0}'.format(idx)\n",
    "\n",
    "span_tags = [tag[score] for score in span_scores]\n",
    "span_df['tag'] = span_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e841cda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b43855dd",
   "metadata": {},
   "source": [
    "**Using pdfminer.six**\n",
    "\n",
    "- Second best. Not as good as pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e94bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.high_level import extract_text, extract_pages\n",
    "from pdfminer.layout import LAParams\n",
    "\n",
    "laparams = LAParams(line_margin=1, boxes_flow=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb59e279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract pages outputs an iterable so we can create list from it\n",
    "pages = [x for x in extract_pages(resume)]\n",
    "\n",
    "for page in range(len(pages)):\n",
    "    print('page_number', page)\n",
    "    text = extract_text(resume, page_numbers=page, laparams=laparams)\n",
    "    print(text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a37ae6ff",
   "metadata": {},
   "source": [
    "**Testing Beautiful Soup**\n",
    "\n",
    "This is to do webscraping of your linkedin profile\n",
    "\n",
    "- Linkedin detects automated scraping and blocks requests\n",
    "- Need to install chrome and chromedriver\n",
    "- Issue with linkedin possibly blocking webscraping\n",
    "- Will have different classnames when actually loggedin\n",
    "- Possibly go for linkedin api?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec03a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "def scrape_linkedin_profile(url):\n",
    "    options = Options()\n",
    "    # running in headless mode\n",
    "    options.add_argument('--headless') \n",
    "    driver = webdriver.Chrome(executable_path='chromedriver', options=options)\n",
    "\n",
    "    driver.get(url)\n",
    "\n",
    "    # wait for the page to load. adjust sleep here\n",
    "    # driver.implicitly_wait(10)\n",
    "    time.sleep(5)\n",
    "\n",
    "    html_content = driver.page_source\n",
    "\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    print(soup)\n",
    "\n",
    "    lis = soup.find_all('li', class_='experience-item')\n",
    "\n",
    "    try:\n",
    "        modal_dismis = driver.find_element(By.CLASS_NAME, 'contextual-sign-in-modal__modal-dismiss')\n",
    "        if modal_dismis:\n",
    "            modal_dismis.click()\n",
    "    except Exception:\n",
    "        print('Already opened')\n",
    "\n",
    "\n",
    "    show_more_buttons = driver.find_elements(By.CLASS_NAME, 'show-more-less-text__button--more')\n",
    "\n",
    "    for button in show_more_buttons:\n",
    "        button.click()\n",
    "\n",
    "    for li in lis:\n",
    "        print(\"Experience\", lis.index(li))\n",
    "        description_more = ''\n",
    "        description_less = ''\n",
    "        \n",
    "        title = get_text(li.find('h3', class_='profile-section-card__title'))\n",
    "        company = get_text(li.find('h4', class_='profile-section-card__subtitle'))\n",
    "        location = get_text(li.find('p', class_='experience-item__location'))\n",
    "\n",
    "        # the class naming is weird in this case. Everything that has show more button will have --more\n",
    "        # modifier and everything else has --less modifier \n",
    "        description_more = get_text(li.find('p', class_='show-more-less-text__text--more'))\n",
    "        description_less = get_text(li.find('p', class_='show-more-less-text__text--less'))\n",
    "\n",
    "        if description_more:\n",
    "            description_list = get_duties(description_more)\n",
    "        elif description_less:\n",
    "            description_list = get_duties(description_less)\n",
    "        else:\n",
    "            description_list = []\n",
    "            \n",
    "        print(title)\n",
    "        print(company)\n",
    "        print(location)\n",
    "        print('Responsibilities: ')\n",
    "        for duty in description_list:\n",
    "            print(duty)\n",
    "        print('\\n')\n",
    "        \n",
    "    driver.quit()\n",
    "\n",
    "def get_text(element):\n",
    "    try:\n",
    "        return element.get_text().strip()\n",
    "    except Exception as e:\n",
    "        return ''\n",
    "    \n",
    "def get_duties(description):\n",
    "    # for some reason the button \"show less\" keeps popping up. Need to remove that\n",
    "    trimmed = description.replace('\\n            \\n\\n    \\n    \\n\\n    \\n        Show less', '')\n",
    "    return trimmed.split('â€¢ ')[1:]\n",
    "\n",
    "\n",
    "scrape_linkedin_profile('https://www.linkedin.com/in/jerick-iquin/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "58002000",
   "metadata": {},
   "source": [
    "**Using pypdf package**\n",
    "\n",
    "- Didn't work on Jek's email. Some of the spaces are not being extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db43e27a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n",
    "\n",
    "reader = PdfReader(resume)\n",
    "number_of_pages = len(reader.pages)\n",
    "\n",
    "for page_number in range(number_of_pages):\n",
    "    page = reader.pages[page_number]\n",
    "    text = page.extract_text()\n",
    "    print(text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8647ce12",
   "metadata": {},
   "source": [
    "**Using pyPDF2**\n",
    "\n",
    "- Didn't work on Jek's email. Some of the spaces are not being extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dce502",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "\n",
    "reader = PdfReader(resume, strict=True)\n",
    "number_of_pages = len(reader.pages)\n",
    "for page_number in range(number_of_pages):\n",
    "    page = reader.pages[page_number]\n",
    "    text = page.extract_text()\n",
    "    print(text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
